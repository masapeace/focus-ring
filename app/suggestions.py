# -*- coding: utf-8 -*-
"""
Focus Ring - æ”¹å–„ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³
ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†æã¨LLMé€£æºã«ã‚ˆã‚‹è¡Œå‹•æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹
"""

import os
from typing import List, Dict, Optional
from datetime import datetime

from .models import DailySummary, AIResponse
from .summarizer import calculate_daily_summary, get_category_distribution, get_time_of_day_productivity
from .db import get_filled_blocks_for_date, get_all_categories


# === ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ”¹å–„ææ¡ˆ ===

def generate_rule_based_suggestions(summary: DailySummary) -> AIResponse:
    """
    ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
    
    Args:
        summary: æ—¥æ¬¡ã‚µãƒãƒªãƒ‡ãƒ¼ã‚¿
        
    Returns:
        AIResponseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    suggestions = []
    
    # 1. å¦¨å®³æ™‚é–“ãƒã‚§ãƒƒã‚¯ï¼ˆdistract_ratio > 0.2ï¼‰
    if summary.distract_ratio > 0.2:
        distract_pct = summary.distract_ratio * 100
        suggestions.append(
            f"âš ï¸ å¦¨å®³æ™‚é–“ãŒ {distract_pct:.1f}% ã¨é«˜ã‚ã§ã™ã€‚"
            f"å‹•ç”»ãƒ»SNSæ™‚é–“ã‚’æ„è­˜çš„ã«æ¸›ã‚‰ã—ã€é›†ä¸­ç’°å¢ƒã‚’æ•´ãˆã¾ã—ã‚‡ã†ã€‚"
        )
    
    # 2. æœ€ä½ç”Ÿç”£æ™‚é–“ãƒã‚§ãƒƒã‚¯ï¼ˆproductive_blocks < 12 = 3æ™‚é–“ï¼‰
    if summary.productive_blocks < 12:
        suggestions.append(
            f"ğŸ“ˆ ç”Ÿç”£çš„ãªæ´»å‹•ãŒ {summary.productive_hours}æ™‚é–“ã§ã—ãŸã€‚"
            f"æœ€ä½3æ™‚é–“ï¼ˆ12ãƒ–ãƒ­ãƒƒã‚¯ï¼‰ã‚’ç›®æ¨™ã«ã€å­¦ç¿’ã‚„ä½œæ¥­æ™‚é–“ã‚’ç¢ºä¿ã—ã¾ã—ã‚‡ã†ã€‚"
        )
    
    # 3. é›†ä¸­ã®é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆdeep_streak_max < 4 = 1æ™‚é–“ï¼‰
    if summary.deep_streak_max < 4:
        suggestions.append(
            f"ğŸ¯ æœ€å¤§é€£ç¶šé›†ä¸­æ™‚é–“ãŒ {summary.deep_streak_max * 15}åˆ†ã§ã—ãŸã€‚"
            f"æœã®2æ™‚é–“ãƒ–ãƒ­ãƒƒã‚¯ãªã©ã€é•·æ™‚é–“é›†ä¸­ã§ãã‚‹æ™‚é–“å¸¯ã‚’ä½œã‚Šã¾ã—ã‚‡ã†ã€‚"
        )
    
    # 4. ã‚«ãƒ†ã‚´ãƒªåˆ‡æ›¿ãŒå¤šã„å ´åˆï¼ˆcontext_switches éå¤šï¼‰
    expected_switches = max(summary.total_filled // 8, 1)
    if summary.context_switches > expected_switches * 2:
        suggestions.append(
            f"ğŸ”„ ã‚«ãƒ†ã‚´ãƒªåˆ‡æ›¿ãŒ {summary.context_switches}å›ã¨å¤šã‚ã§ã™ã€‚"
            f"åŒã˜ç¨®é¡ã®ä½œæ¥­ã‚’ã¾ã¨ã‚ã¦è¡Œã†ã¨åŠ¹ç‡ãŒä¸ŠãŒã‚Šã¾ã™ã€‚"
        )
    
    # 5. å…¥åŠ›ä¸è¶³ãƒã‚§ãƒƒã‚¯ï¼ˆtotal_filled < 40 = åŠæ—¥ï¼‰
    if summary.total_filled < 40:
        suggestions.append(
            f"ğŸ“ å…¥åŠ›ãƒ–ãƒ­ãƒƒã‚¯ãŒ {summary.total_filled}/80 ã§ã™ã€‚"
            f"è¡Œå‹•ã®è¨˜éŒ²ã‚’ç¿’æ…£åŒ–ã—ã¦ã€æ”¹å–„ç‚¹ã‚’è¦‹ã¤ã‘ã‚„ã™ãã—ã¾ã—ã‚‡ã†ã€‚"
        )
    
    # 6. é›†ä¸­åº¦å¹³å‡ãƒã‚§ãƒƒã‚¯
    if summary.avg_focus_productive and summary.avg_focus_productive < 3.0:
        suggestions.append(
            f"ğŸ’ª ç”Ÿç”£çš„æ´»å‹•ã®å¹³å‡é›†ä¸­åº¦ãŒ {summary.avg_focus_productive:.1f}/5.0 ã§ã™ã€‚"
            f"ç’°å¢ƒã‚’æ•´ãˆãŸã‚Šã€ã‚¿ã‚¹ã‚¯ã‚’ç´°åˆ†åŒ–ã—ã¦é›†ä¸­åº¦ã‚’ä¸Šã’ã¦ã„ãã¾ã—ã‚‡ã†ã€‚"
        )
    
    # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªè¦ç´ ã‚‚å«ã‚ã‚‹
    positive_points = []
    
    if summary.productive_hours >= 3.0:
        positive_points.append(f"ç”Ÿç”£çš„æ™‚é–“ {summary.productive_hours}æ™‚é–“é”æˆ")
    
    if summary.deep_streak_max >= 6:  # 1.5æ™‚é–“ä»¥ä¸Š
        positive_points.append(f"é€£ç¶šé›†ä¸­ {summary.deep_streak_max * 15}åˆ†é”æˆ")
    
    if summary.distract_ratio <= 0.1:
        positive_points.append("å¦¨å®³æ™‚é–“ã‚’ä½ãæŠ‘åˆ¶")
    
    if summary.focus_score >= 10:
        positive_points.append(f"é«˜ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚¹ã‚³ã‚¢ {summary.focus_score:.1f}")
    
    # ç·æ‹¬ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
    summary_text = generate_summary_comment(summary, positive_points)
    
    # ææ¡ˆãŒå°‘ãªã„å ´åˆã¯ä¸€èˆ¬çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¿½åŠ 
    if len(suggestions) < 2:
        suggestions.extend([
            "ğŸŒ… æœã®æ™‚é–“å¸¯ã¯é›†ä¸­åŠ›ãŒé«˜ã„ã®ã§ã€é‡è¦ãªã‚¿ã‚¹ã‚¯ã«å……ã¦ã¾ã—ã‚‡ã†ã€‚",
            "â° 15åˆ†ã‚¿ã‚¤ãƒãƒ¼ã‚’ä½¿ã£ã¦é›†ä¸­ã¨ä¼‘æ†©ã®ãƒªã‚ºãƒ ã‚’ä½œã‚Šã¾ã—ã‚‡ã†ã€‚",
            "ğŸ“± ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚’åˆ¥ã®éƒ¨å±‹ã«ç½®ã„ã¦ã€èª˜æƒ‘ã‚’æ¸›ã‚‰ã—ã¾ã—ã‚‡ã†ã€‚"
        ])
    
    return AIResponse(
        suggestions=suggestions[:5],  # æœ€å¤§5ã¤ã¾ã§
        summary=summary_text,
        is_ai_generated=False
    )


def generate_summary_comment(summary: DailySummary, positive_points: List[str]) -> str:
    """ç·æ‹¬ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
    
    if summary.focus_score >= 15:
        level = "ç´ æ™´ã‚‰ã—ã„"
        emoji = "ğŸ‰"
    elif summary.focus_score >= 10:
        level = "è‰¯å¥½"
        emoji = "ğŸ‘"
    elif summary.focus_score >= 5:
        level = "æ™®é€š"
        emoji = "ğŸ“ˆ"
    else:
        level = "è¦æ”¹å–„"
        emoji = "ğŸ’ª"
    
    base_comment = f"{emoji} ä»Šæ—¥ã®ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚¹ã‚³ã‚¢ã¯ {summary.focus_score:.1f} ã§{level}ã§ã—ãŸã€‚"
    
    if positive_points:
        positive_text = "ã€".join(positive_points)
        base_comment += f" {positive_text}ãªã©ã€è‰¯ã„ç‚¹ã‚‚ã‚ã‚Šã¾ã—ãŸã€‚"
    
    if summary.focus_score < 10:
        base_comment += " æ˜æ—¥ã¯ã•ã‚‰ã«é›†ä¸­ã§ãã‚‹ç’°å¢ƒã‚’ä½œã£ã¦é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼"
    else:
        base_comment += " ã“ã®èª¿å­ã§ç¶™ç¶šã—ã¦ã„ãã¾ã—ã‚‡ã†ï¼"
    
    return base_comment


# === LLMé€£æºæ”¹å–„ææ¡ˆ ===

def generate_ai_suggestions(date: str) -> AIResponse:
    """
    LLMã‚’ä½¿ç”¨ã—ãŸè©³ç´°ãªæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
    
    Args:
        date: å¯¾è±¡æ—¥ (YYYY-MM-DD)
        
    Returns:
        AIResponseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰API ã‚­ãƒ¼ã‚’å–å¾—
    api_key = os.getenv('LLM_API_KEY')
    
    if not api_key:
        # API ã‚­ãƒ¼ãŒãªã„å ´åˆã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        summary = calculate_daily_summary(date)
        return generate_rule_based_suggestions(summary)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿åé›†
        summary = calculate_daily_summary(date)
        category_dist = get_category_distribution(date)
        time_productivity = get_time_of_day_productivity(date)
        filled_blocks = get_filled_blocks_for_date(date)
        
        # LLMç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        context = build_llm_context(date, summary, category_dist, time_productivity, filled_blocks)
        
        # LLM APIå‘¼ã³å‡ºã—
        response = call_llm_api(context, api_key)
        
        return AIResponse(
            suggestions=response.get('suggestions', []),
            summary=response.get('summary', ''),
            is_ai_generated=True
        )
        
    except Exception as e:
        print(f"LLM API ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        summary = calculate_daily_summary(date)
        fallback_response = generate_rule_based_suggestions(summary)
        fallback_response.summary += " (LLMæ¥ç¶šã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†æ)"
        return fallback_response


def build_llm_context(date: str, summary: DailySummary, 
                     category_dist: Dict[str, Dict[str, float]], 
                     time_productivity: Dict[str, float],
                     filled_blocks: List) -> str:
    """LLMç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰"""
    
    # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±å–å¾—
    categories = get_all_categories()
    category_info = {cat.code: f"{cat.label} (é‡ã¿: {cat.weight})" for cat in categories}
    
    context = f"""
æ—¥ä»˜: {date}
ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚¹ã‚³ã‚¢: {summary.focus_score:.1f} (ç”Ÿã‚¹ã‚³ã‚¢: {summary.raw_score:.1f}, é€£ç¶šé›†ä¸­: {summary.deep_streak_max}, åˆ‡æ›¿ãƒšãƒŠãƒ«ãƒ†ã‚£: {summary.penalty:.1f})

æ´»å‹•æ™‚é–“:
- ç”Ÿç”£çš„: {summary.productive_hours}æ™‚é–“ ({summary.productive_blocks}ãƒ–ãƒ­ãƒƒã‚¯)
- å¦¨å®³çš„: {summary.distract_hours}æ™‚é–“ ({summary.distract_blocks}ãƒ–ãƒ­ãƒƒã‚¯)
- ä¸­æ€§: {summary.neutral_blocks}ãƒ–ãƒ­ãƒƒã‚¯
- å¦¨å®³æ™‚é–“å‰²åˆ: {summary.distract_ratio * 100:.1f}%

é›†ä¸­åº¦: ç”Ÿç”£çš„æ´»å‹•ã®å¹³å‡ {summary.avg_focus_productive or 'N/A'}/5.0

ã‚«ãƒ†ã‚´ãƒªåˆ¥æ™‚é–“åˆ†å¸ƒ:
"""
    
    for category, data in category_dist.items():
        category_name = category_info.get(category, category)
        context += f"- {category_name}: {data['hours']}æ™‚é–“ ({data['percentage']:.1f}%)\n"
    
    context += "\næ™‚é–“å¸¯åˆ¥ç”Ÿç”£æ€§:\n"
    for period, score in time_productivity.items():
        context += f"- {period}: {score:.1f}\n"
    
    context += f"""
ã‚«ãƒ†ã‚´ãƒªåˆ‡æ›¿å›æ•°: {summary.context_switches}å›
å…¥åŠ›æ¸ˆã¿ãƒ–ãƒ­ãƒƒã‚¯: {summary.total_filled}/80

ã“ã®äººã®1æ—¥ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã€ç”Ÿç”£æ€§å‘ä¸Šã®ãŸã‚ã®å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’3-5ã¤æä¾›ã—ã¦ãã ã•ã„ã€‚
ã¾ãŸã€ä»Šæ—¥ã®ç·æ‹¬ã‚³ãƒ¡ãƒ³ãƒˆã‚‚å«ã‚ã¦ãã ã•ã„ã€‚
"""
    
    return context


def call_llm_api(context: str, api_key: str) -> Dict:
    """LLM APIã‚’å‘¼ã³å‡ºã—ï¼ˆOpenAIå½¢å¼ã‚’æƒ³å®šï¼‰"""
    try:
        import openai
        
        client = openai.OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯ç”Ÿç”£æ€§å‘ä¸Šã®ã‚³ãƒ¼ãƒã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®1æ—¥ã®è¡Œå‹•ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªæ”¹å–„ææ¡ˆã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚"
                },
                {
                    "role": "user", 
                    "content": context
                }
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰
        content = response.choices[0].message.content
        
        # ææ¡ˆã¨ç·æ‹¬ã‚’åˆ†é›¢ï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰
        lines = content.split('\n')
        suggestions = []
        summary = ""
        
        in_suggestions = False
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            if 'ææ¡ˆ' in line or 'æ”¹å–„' in line:
                in_suggestions = True
                continue
            elif 'ç·æ‹¬' in line or 'ã¾ã¨ã‚' in line:
                in_suggestions = False
                continue
            
            if in_suggestions and (line.startswith('-') or line.startswith('â€¢') or line.startswith('1.')):
                suggestions.append(line.lstrip('-â€¢1234567890. '))
            elif not in_suggestions:
                summary += line + " "
        
        return {
            'suggestions': suggestions[:5] if suggestions else ["LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚¨ãƒ©ãƒ¼"],
            'summary': summary.strip() or "LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚¨ãƒ©ãƒ¼"
        }
        
    except Exception as e:
        raise Exception(f"OpenAI APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")


# === å…¬é–‹API ===

def get_daily_suggestions(date: str) -> AIResponse:
    """
    æŒ‡å®šæ—¥ã®æ”¹å–„ææ¡ˆã‚’å–å¾—ï¼ˆLLM or ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
    
    Args:
        date: å¯¾è±¡æ—¥ (YYYY-MM-DD)
        
    Returns:
        AIResponseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    try:
        return generate_ai_suggestions(date)
    except Exception as e:
        print(f"ææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯åŸºæœ¬çš„ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ææ¡ˆ
        summary = calculate_daily_summary(date)
        return generate_rule_based_suggestions(summary)


def get_quick_tips() -> List[str]:
    """ä¸€èˆ¬çš„ãªç”Ÿç”£æ€§å‘ä¸Šã®ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚£ãƒƒãƒ—ã‚’å–å¾—"""
    return [
        "ğŸŒ… èµ·åºŠå¾Œã®2æ™‚é–“ã¯ã€Œã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¿ã‚¤ãƒ ã€ã€‚é‡è¦ãªã‚¿ã‚¹ã‚¯ã«å……ã¦ã¾ã—ã‚‡ã†ã€‚",
        "ğŸ“± ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚’åˆ¥å®¤ã«ç½®ã„ã¦ã€èª˜æƒ‘ã‚’ç‰©ç†çš„ã«é ã–ã‘ã¾ã—ã‚‡ã†ã€‚",
        "â° ãƒãƒ¢ãƒ‰ãƒ¼ãƒ­ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ï¼ˆ25åˆ†é›†ä¸­â†’5åˆ†ä¼‘æ†©ï¼‰ã‚’è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚",
        "ğŸ§˜ ç‘æƒ³ã‚„æ·±å‘¼å¸ã§é›†ä¸­åŠ›ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ç¿’æ…£ã‚’ä½œã‚Šã¾ã—ã‚‡ã†ã€‚",
        "ğŸ“ å‰æ—¥ã®å¤œã«ç¿Œæ—¥ã®ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚",
        "ğŸ’§ ååˆ†ãªæ°´åˆ†è£œçµ¦ã§è„³ã®åƒãã‚’è‰¯å¥½ã«ä¿ã¡ã¾ã—ã‚‡ã†ã€‚",
        "ğŸš¶ é©åº¦ãªé‹å‹•ã§è¡€æµã‚’æ”¹å–„ã—ã€é›†ä¸­åŠ›ã‚’é«˜ã‚ã¾ã—ã‚‡ã†ã€‚",
        "ğŸµ é›†ä¸­ã§ãã‚‹éŸ³æ¥½ã‚„ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºã‚’æ´»ç”¨ã—ã¾ã—ã‚‡ã†ã€‚"
    ]


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    from .utils import get_today
    
    print("=== Suggestions Test ===")
    
    today = get_today()
    print(f"ä»Šæ—¥ã®æ”¹å–„ææ¡ˆãƒ†ã‚¹ãƒˆ: {today}")
    
    response = get_daily_suggestions(today)
    print(f"ç·æ‹¬: {response.summary}")
    print("ææ¡ˆ:")
    for i, suggestion in enumerate(response.suggestions, 1):
        print(f"  {i}. {suggestion}")
    print(f"AIç”Ÿæˆ: {response.is_ai_generated}")